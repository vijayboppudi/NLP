{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d1baaea",
   "metadata": {},
   "source": [
    "# NLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bfd6cb65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9876543210', '(987)-654-4321']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting required Text from given data using Regular Expression\n",
    "\n",
    "import re\n",
    "\n",
    "text = \"\"\"Employee phone number is 9876543210,(987)-654-4321 and his salary is 1500$ and his expenses are 500 dollars and you\n",
    "        can contact them via email also. The email is abc_a@gmail.com, xyz_123@gmail.com, ccc@xyz.io and their order numbers \n",
    "        are order 41215, order id 2213, order # 1234\"\"\"\n",
    "\n",
    "pattern1 = \"\\d{10}|\\(\\d{3}\\)\\-\\d{3}\\-\\d{4}\"\n",
    "pattern2 = \"\\d{4}\\$|\\d{3} dollars\"\n",
    "pattern3 = \"[a-zA-Z0-9_]*@[a-zA-Z0-9_]*.[a-zA-Z]*\"\n",
    "pattern4 = \"order[^\\d]*(\\d*)\"\n",
    "match1 = re.findall(pattern1, text)\n",
    "match2 = re.findall(pattern2, text)\n",
    "match3 = re.findall(pattern3, text)\n",
    "match4 = re.findall(pattern4, text)\n",
    "match1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96998005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1500$', '500 dollars']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1cfdedd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abc_a@gmail.com', 'xyz_123@gmail.com', 'ccc@xyz.io']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3df08064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['41215', '2213', '1234']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97f6b331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['elonmusk', 'teslarati', 'dummy_tesla', 'dummy_2_tesla']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = '''Follow our leader Elon musk on Twitter \n",
    "        here: https://twitter.com/elonmusk, more information \n",
    "        on Tesla's products can be found at https://www.tesla.com/. \n",
    "        Also here are leading influencers for tesla-related news, \n",
    "        https://twitter.com/teslarati\n",
    "        https://twitter.com/dummy_tesla\n",
    "        https://twitter.com/dummy_2_tesla'''\n",
    "\n",
    "pattern = \"https\\:\\/\\/twitter.com\\/([a-zA-Z0-9_]*)\"\n",
    "match = re.findall(pattern, data)\n",
    "match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "89430e6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Marta Sharapova'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = '''Name: Marta Sharapova Date: 5/11/2022\n",
    "\n",
    "    Address: 9 tennis court, new Russia, DC\n",
    "\n",
    "    Prednisone 20 mg\n",
    "    Lialda 2.4 gram\n",
    "\n",
    "    Directions:\n",
    "\n",
    "    Prednisone, Taper 5 mg every 3 days,\n",
    "    Finish in 2.5 weeks a\n",
    "    Lialda - take 2 pill everyday for 1 month\n",
    "\n",
    "    Refill: 2 times'''\n",
    "\n",
    "pattern1 = \"Name:(.*)Date\"\n",
    "pattern2 = \"Address:(.*)\"\n",
    "pattern3 = \"Address[^\\n]*(.*)Directions\"\n",
    "pattern4 = \"Directions:[^\\n]*(.*)Refill\"\n",
    "pattern5 = \"Refill:(.*)\"\n",
    "\n",
    "match1 = re.findall(pattern1, text)\n",
    "match2 = re.findall(pattern2, text)\n",
    "match3 = re.findall(pattern3, text, flags=re.DOTALL)\n",
    "match4 = re.findall(pattern4, text, flags=re.DOTALL)\n",
    "match5 = re.findall(pattern5, text)\n",
    "\n",
    "match1[0].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "701659d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9 tennis court, new Russia, DC'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match2[0].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8d640e1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Prednisone 20 mg\\n    Lialda 2.4 gram'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match3[0].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6b81ab55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Prednisone, Taper 5 mg every 3 days,\\n    Finish in 2.5 weeks a\\n    Lialda - take 2 pill everyday for 1 month'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match4[0].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "68b08e10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2 times'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match5[0].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820109e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9aa1a795",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python\n",
      "is\n",
      "most\n",
      "widely\n",
      "used\n",
      "language\n",
      "in\n",
      "the\n",
      "world\n",
      "at\n",
      "no.1\n",
      "position\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "# Tokenization in spacy\n",
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Python is most widely used language in the world at no.1 position.\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b919d820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['virat@gmail.com', 'rohit@email.com']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = '''virat@gmail.com\n",
    "         virat kohli\n",
    "         rohit@email.com\n",
    "         Rohit sharma'''\n",
    "\n",
    "doc =nlp(text)\n",
    "email = []\n",
    "for token in doc:\n",
    "    if token.like_email:\n",
    "        email.append(token.text)\n",
    "email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0dabc81f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://www.data.gov/',\n",
       " 'http://www.science',\n",
       " 'http://data.gov.uk/.',\n",
       " 'http://www3.norc.org/gss+website/',\n",
       " 'http://www.europeansocialsurvey.org/.']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting all urls from a given text\n",
    "\n",
    "text='''\n",
    "Look for data to help you address the question. Governments are good\n",
    "sources because data from public research is often freely available. Good\n",
    "places to start include http://www.data.gov/, and http://www.science.\n",
    "gov/, and in the United Kingdom, http://data.gov.uk/.\n",
    "Two of my favorite data sets are the General Social Survey at http://www3.norc.org/gss+website/, \n",
    "and the European Social Survey at http://www.europeansocialsurvey.org/.\n",
    "'''\n",
    "\n",
    "doc = nlp(text)\n",
    "url = []\n",
    "\n",
    "for token in doc:\n",
    "    if token.like_url:\n",
    "        url.append(token.text)\n",
    "        \n",
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bc8e9b26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://www.data.gov/',\n",
       " 'http://www.science',\n",
       " 'http://data.gov.uk/.',\n",
       " 'http://www3.norc.org/gss+website/',\n",
       " 'http://www.europeansocialsurvey.org/.']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_websites = [token.text for token in doc if token.like_url]\n",
    "data_websites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9645e4c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two $\n",
      "500 €\n"
     ]
    }
   ],
   "source": [
    "transactions = \"Tony gave two $ to Peter, Bruce gave 500 € to Steve\"\n",
    "\n",
    "doc = nlp(transactions)\n",
    "for token in doc:\n",
    "    if token.like_num and doc[token.i+1].is_currency:\n",
    "        print(token.text, doc[token.i+1].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "00a50256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0e2b7762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python | PROPN | Python\n",
      "is | AUX | be\n",
      "most | ADV | most\n",
      "widely | ADV | widely\n",
      "used | VERB | use\n",
      "language | NOUN | language\n",
      "in | ADP | in\n",
      "the | DET | the\n",
      "world | NOUN | world\n",
      "at | ADP | at\n",
      "no.1 | ADJ | no.1\n",
      "position | NOUN | position\n",
      ". | PUNCT | .\n"
     ]
    }
   ],
   "source": [
    "# NLP Pipeline\n",
    "\n",
    "doc = nlp(\"Python is most widely used language in the world at no.1 position.\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token, \"|\",token.pos_,\"|\",token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "767c2570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla Inc | ORG | Companies, agencies, institutions, etc.\n",
      "$45 billion | MONEY | Monetary values, including unit\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Tesla Inc bought twitter for $45 billion\")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, \"|\", ent.label_, \"|\", spacy.explain(ent.label_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bf56cb7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft | ORG | Companies, agencies, institutions, etc.\n",
      "Bill Gates | PERSON | People, including fictional\n",
      "Paul Allen | PERSON | People, including fictional\n",
      "Albuquerque | GPE | Countries, cities, states\n",
      "April 4, 1975 | DATE | Absolute or relative dates or periods\n"
     ]
    }
   ],
   "source": [
    "text = \"Microsoft was founded by Bill Gates and Paul Allen in Albuquerque on April 4, 1975.\"\n",
    "doc = nlp(text)\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text,\"|\", ent.label_,\"|\", spacy.explain(ent.label_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8c7308a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating | eat\n",
      "eats | eat\n",
      "eat | eat\n",
      "ate | ate\n",
      "adjustable | adjust\n",
      "rafting | raft\n",
      "ability | abil\n",
      "meeting | meet\n"
     ]
    }
   ],
   "source": [
    "# Stemming using NLTK\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "words = [\"eating\",\"eats\",\"eat\",\"ate\",\"adjustable\",\"rafting\",\"ability\",\"meeting\"]\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "for word in words:\n",
    "    print(word, \"|\", stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "47aa35c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating | eat\n",
      "eats | eat\n",
      "eat | eat\n",
      "ate | eat\n",
      "adjustable | adjustable\n",
      "rafting | raft\n",
      "ability | ability\n",
      "meeting | meeting\n",
      "better | well\n"
     ]
    }
   ],
   "source": [
    "# lemmatization using spacy\n",
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"eating eats eat ate adjustable rafting ability meeting better\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token, \"|\", token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "823762e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bro | bro\n",
      ", | ,\n",
      "you | you\n",
      "wanna | wanna\n",
      "go | go\n",
      "? | ?\n",
      "Brah | Brah\n",
      ", | ,\n",
      "do | do\n",
      "n't | not\n",
      "say | say\n",
      "no | no\n",
      "! | !\n",
      "I | I\n",
      "am | be\n",
      "exhausted | exhaust\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Bro, you wanna go? Brah, don't say no! I am exhausted\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token, \"|\", token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "21f2e45f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bro | Brother\n",
      ", | ,\n",
      "you | you\n",
      "wanna | wanna\n",
      "go | go\n",
      "? | ?\n",
      "Brah | Brother\n",
      ", | ,\n",
      "do | do\n",
      "n't | not\n",
      "say | say\n",
      "no | no\n",
      "! | !\n",
      "I | I\n",
      "am | be\n",
      "exhausted | exhaust\n"
     ]
    }
   ],
   "source": [
    "ar = nlp.get_pipe(\"attribute_ruler\")\n",
    "ar.add([[{\"TEXT\":\"Bro\"}],[{\"TEXT\":\"Brah\"}]], {\"LEMMA\":\"Brother\"})\n",
    "\n",
    "doc = nlp(\"Bro, you wanna go? Brah, don't say no! I am exhausted\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token, \"|\", token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6cc0e111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "India | PROPN | proper noun\n",
      "has | AUX | auxiliary\n",
      "succesfully | ADV | adverb\n",
      "launched | VERB | verb\n",
      "chandrayaan-3 | PROPN | proper noun\n",
      "from | ADP | adposition\n",
      "satish | PROPN | proper noun\n",
      "dhawan | PROPN | proper noun\n",
      "space | NOUN | noun\n",
      "center | NOUN | noun\n"
     ]
    }
   ],
   "source": [
    "# NLP Parts Of Speech Tagging\n",
    "\n",
    "ca = nlp(\"India has succesfully launched chandrayaan-3 from satish dhawan space center\")\n",
    "\n",
    "for token in ca:\n",
    "    print(token, \"|\", token.pos_, \"|\", spacy.explain(token.pos_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "eb24db4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wow | INTJ | UH | interjection\n",
      "! | PUNCT | . | punctuation mark, sentence closer\n",
      "India | PROPN | NNP | noun, proper singular\n",
      "won | VERB | VBD | verb, past tense\n",
      "the | DET | DT | determiner\n",
      "cricket | NOUN | NN | noun, singular or mass\n",
      "worldcup | NOUN | NN | noun, singular or mass\n",
      "and | CCONJ | CC | conjunction, coordinating\n",
      "became | VERB | VBD | verb, past tense\n",
      "no.1 | ADJ | JJ | adjective (English), other noun-modifier (Chinese)\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Wow! India won the cricket worldcup and became no.1\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token, \"|\", token.pos_, \"|\", token.tag_, \"|\", spacy.explain(token.tag_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "89815927",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_text=\"\"\"Microsoft Corp. today announced the following results for the quarter ended December 31, 2021, as compared to the corresponding period of last fiscal year:\n",
    "\n",
    "·         Revenue was $51.7 billion and increased 20%\n",
    "·         Operating income was $22.2 billion and increased 24%\n",
    "·         Net income was $18.8 billion and increased 21%\n",
    "·         Diluted earnings per share was $2.48 and increased 22%\n",
    "“Digital technology is the most malleable resource at the world’s disposal to overcome constraints and reimagine everyday work and life,” said Satya Nade\"lla, chairman and chief executive officer of Microsoft. “As tech as a percentage of global GDP continues to increase, we are innovating and investing across diverse and growing markets, with a common underlying technology stack and an operating model that reinforces a common strategy, culture, and sense of purpose.”\n",
    "“Solid commercial execution, represented by strong bookings growth driven by long-term Azure commitments, increased Microsoft Cloud revenue\"\"\"\n",
    "\n",
    "doc = nlp(learning_text)\n",
    "\n",
    "filtered_tokens = []\n",
    "for token in doc:\n",
    "    if token.pos_ not in [\"PUNCT\",\"SPACE\",\"X\"]:\n",
    "        filtered_tokens.append(token) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5f6b511a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{96: 10,\n",
       " 92: 40,\n",
       " 100: 23,\n",
       " 90: 9,\n",
       " 85: 13,\n",
       " 93: 13,\n",
       " 97: 23,\n",
       " 98: 1,\n",
       " 84: 17,\n",
       " 103: 10,\n",
       " 87: 6,\n",
       " 99: 4,\n",
       " 89: 11,\n",
       " 86: 2,\n",
       " 94: 3,\n",
       " 95: 2}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = doc.count_by(spacy.attrs.POS)\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b32f3d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROPN | 10\n",
      "NOUN | 40\n",
      "VERB | 23\n",
      "DET | 9\n",
      "ADP | 13\n",
      "NUM | 13\n",
      "PUNCT | 23\n",
      "SCONJ | 1\n",
      "ADJ | 17\n",
      "SPACE | 10\n",
      "AUX | 6\n",
      "SYM | 4\n",
      "CCONJ | 11\n",
      "ADV | 2\n",
      "PART | 3\n",
      "PRON | 2\n"
     ]
    }
   ],
   "source": [
    "for k,v in count.items():\n",
    "    print(doc.vocab[k].text, \"|\", v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "37a46d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting Noun and Num Parts Of Speech From text\n",
    "\n",
    "text = '''Inflation rose again in April, continuing a climb that has pushed consumers to the brink and is threatening the \n",
    "          economic expansion, the Bureau of Labor Statistics reported Wednesday.\\n\\nThe consumer price index, a broad-based \n",
    "          measure of prices for goods and services, increased 8.3% from a year ago, higher than the Dow Jones estimate for \n",
    "          an 8.1% gain. That represented a slight ease from Marchâ€™s peak but was still close to the highest level since the \n",
    "          summer of 1982.\\n\\nRemoving volatile food and ene'''\n",
    "\n",
    "doc = nlp(text)\n",
    "Noun_tokens = []\n",
    "Num_tokens = []\n",
    "\n",
    "for token in doc:\n",
    "    if token.pos_ == \"NOUN\":\n",
    "        Noun_tokens.append(token)\n",
    "    elif token.pos_ == \"NUM\":\n",
    "        Num_tokens.append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c0968c05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8.3, 8.1, 1982]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Num_tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a319fbdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Inflation,\n",
       " climb,\n",
       " consumers,\n",
       " brink,\n",
       " expansion,\n",
       " consumer,\n",
       " price,\n",
       " index,\n",
       " measure,\n",
       " prices]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Noun_tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3064e488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{92: 25,\n",
       " 100: 9,\n",
       " 86: 4,\n",
       " 85: 11,\n",
       " 96: 7,\n",
       " 97: 9,\n",
       " 90: 12,\n",
       " 95: 2,\n",
       " 87: 3,\n",
       " 89: 4,\n",
       " 103: 6,\n",
       " 84: 6,\n",
       " 93: 3,\n",
       " 94: 1,\n",
       " 98: 1}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = doc.count_by(spacy.attrs.POS)\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a6281cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOUN | 25\n",
      "VERB | 9\n",
      "ADV | 4\n",
      "ADP | 11\n",
      "PROPN | 7\n",
      "PUNCT | 9\n",
      "DET | 12\n",
      "PRON | 2\n",
      "AUX | 3\n",
      "CCONJ | 4\n",
      "SPACE | 6\n",
      "ADJ | 6\n",
      "NUM | 3\n",
      "PART | 1\n",
      "SCONJ | 1\n"
     ]
    }
   ],
   "source": [
    "for k,v in count.items():\n",
    "    print(doc.vocab[k].text, \"|\", v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef415d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mukesh Ambani | PERSON | People, including fictional\n",
      "India | GPE | Countries, cities, states\n",
      "Reliance Industries | ORG | Companies, agencies, institutions, etc.\n",
      "$82 billion | MONEY | Monetary values, including unit\n"
     ]
    }
   ],
   "source": [
    "# Named Entity Recognition in NLP using spacy\n",
    "\n",
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "doc = nlp(\"Mukesh Ambani from India is the chairman of Reliance Industries earning $82 billion\")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent, \"|\", ent.label_, \"|\", spacy.explain(ent.label_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb555aed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Mukesh Ambani\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " from \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    India\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " is the chairman of \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Reliance Industries\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " earning \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    $82 billion\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "20368211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[India, Delhi, Gujarat, Tamilnadu, Andhrapradesh, Assam, Bihar]\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"Kiran want to know the famous foods in each state of India. So, he opened Google and search for this question. Google showed that\n",
    "in Delhi it is Chaat, in Gujarat it is Dal Dhokli, in Tamilnadu it is Pongal food, in Andhrapradesh it is Biryani, in Assam it is Papaya Khar,\n",
    "in Bihar it is Litti Chowkha and so on for all other states\"\"\"\n",
    "\n",
    "doc = nlp(text)\n",
    "locations = []\n",
    "\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ == \"GPE\":\n",
    "        locations.append(ent)\n",
    "\n",
    "print(locations)\n",
    "print(len(locations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "576964c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text representation - Bag of Words(BOW)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3bca5076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: enron methanol ; meter # : 988291\\r\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: hpl nom for january 9 , 2001\\r\\n( see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: neon retreat\\r\\nho ho ho , we ' re ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: re : indian springs\\r\\nthis deal is t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   ham  Subject: enron methanol ; meter # : 988291\\r\\n...\n",
       "1   ham  Subject: hpl nom for january 9 , 2001\\r\\n( see...\n",
       "2   ham  Subject: neon retreat\\r\\nho ho ho , we ' re ar...\n",
       "3  spam  Subject: photoshop , windows , office . cheap ...\n",
       "4   ham  Subject: re : indian springs\\r\\nthis deal is t..."
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\boppu\\OneDrive\\Desktop\\spam_ham_dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ed16a8ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     3672\n",
       "spam    1499\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "66a0362d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5171, 3)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7ae80864",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"spam\"] = df[\"label\"].apply(lambda x: 1 if x == \"spam\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "cd84a1e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: enron methanol ; meter # : 988291\\r\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: hpl nom for january 9 , 2001\\r\\n( see...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: neon retreat\\r\\nho ho ho , we ' re ar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: re : indian springs\\r\\nthis deal is t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text  spam\n",
       "0   ham  Subject: enron methanol ; meter # : 988291\\r\\n...     0\n",
       "1   ham  Subject: hpl nom for january 9 , 2001\\r\\n( see...     0\n",
       "2   ham  Subject: neon retreat\\r\\nho ho ho , we ' re ar...     0\n",
       "3  spam  Subject: photoshop , windows , office . cheap ...     1\n",
       "4   ham  Subject: re : indian springs\\r\\nthis deal is t...     0"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f9a23a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df.text, df.spam, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "dda93440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4136,)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4a711051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1035,)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3387a74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "x_train_cv = cv.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "344f72bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4136, 44966)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_cv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "2f74a4d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(x_train_cv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ac38152b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       742\n",
      "           1       0.97      0.95      0.96       293\n",
      "\n",
      "    accuracy                           0.98      1035\n",
      "   macro avg       0.98      0.97      0.97      1035\n",
      "weighted avg       0.98      0.98      0.98      1035\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "x_test_cv = cv.transform(x_test)\n",
    "\n",
    "y_pred = model.predict(x_test_cv)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "3cf4c286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails = [\n",
    "    \"Let us play cricket\",\n",
    "    \"upto 20% discount $10000, hurry up offer closes soon\"\n",
    "]\n",
    "\n",
    "emails_count = cv.transform(emails)\n",
    "model.predict(emails_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e64b7989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn pipeline\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "clf = Pipeline([\n",
    "    (\"vectorizer\", CountVectorizer()),\n",
    "    (\"nb\", MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e0910b81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;, CountVectorizer()), (&#x27;nb&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;, CountVectorizer()), (&#x27;nb&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('vectorizer', CountVectorizer()), ('nb', MultinomialNB())])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "a876e142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       742\n",
      "           1       0.97      0.95      0.96       293\n",
      "\n",
      "    accuracy                           0.98      1035\n",
      "   macro avg       0.98      0.97      0.97      1035\n",
      "weighted avg       0.98      0.98      0.98      1035\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8dfda1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stop words and removing of stop words\n",
    "\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "len(STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb0a2528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We\n",
      "just\n",
      "our\n",
      "the\n",
      "part\n",
      "is\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "doc = nlp(\"We just opened our wings, the flying part is coming soon\")\n",
    "\n",
    "for token in doc:\n",
    "    if token.is_stop:\n",
    "        print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "87490dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    doc = nlp(text)\n",
    "    no_stop_words = [token.text for token in doc if not token.is_stop and not token.is_punct]\n",
    "    return \" \".join(no_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3abfd89a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'opened wings flying coming soon'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(\"We just opened our wings, the flying part is coming soon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4b27293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13087, 6)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_json(r\"C:\\Users\\boppu\\OneDrive\\Desktop\\combined.json\", lines = True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56154bcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>contents</th>\n",
       "      <th>date</th>\n",
       "      <th>topics</th>\n",
       "      <th>components</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>Convicted Bomb Plotter Sentenced to 30 Years</td>\n",
       "      <td>PORTLAND, Oregon. – Mohamed Osman Mohamud, 23,...</td>\n",
       "      <td>2014-10-01T00:00:00-04:00</td>\n",
       "      <td>[]</td>\n",
       "      <td>[National Security Division (NSD)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12-919</td>\n",
       "      <td>$1 Million in Restitution Payments Announced t...</td>\n",
       "      <td>WASHINGTON – North Carolina’s Waccamaw River...</td>\n",
       "      <td>2012-07-25T00:00:00-04:00</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Environment and Natural Resources Division]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11-1002</td>\n",
       "      <td>$1 Million Settlement Reached for Natural Reso...</td>\n",
       "      <td>BOSTON– A $1-million settlement has been...</td>\n",
       "      <td>2011-08-03T00:00:00-04:00</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Environment and Natural Resources Division]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10-015</td>\n",
       "      <td>10 Las Vegas Men Indicted \\r\\nfor Falsifying V...</td>\n",
       "      <td>WASHINGTON—A federal grand jury in Las Vegas...</td>\n",
       "      <td>2010-01-08T00:00:00-05:00</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Environment and Natural Resources Division]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18-898</td>\n",
       "      <td>$100 Million Settlement Will Speed Cleanup Wor...</td>\n",
       "      <td>The U.S. Department of Justice, the U.S. Envir...</td>\n",
       "      <td>2018-07-09T00:00:00-04:00</td>\n",
       "      <td>[Environment]</td>\n",
       "      <td>[Environment and Natural Resources Division]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                              title  \\\n",
       "0     None       Convicted Bomb Plotter Sentenced to 30 Years   \n",
       "1  12-919   $1 Million in Restitution Payments Announced t...   \n",
       "2  11-1002  $1 Million Settlement Reached for Natural Reso...   \n",
       "3   10-015  10 Las Vegas Men Indicted \\r\\nfor Falsifying V...   \n",
       "4   18-898  $100 Million Settlement Will Speed Cleanup Wor...   \n",
       "\n",
       "                                            contents  \\\n",
       "0  PORTLAND, Oregon. – Mohamed Osman Mohamud, 23,...   \n",
       "1    WASHINGTON – North Carolina’s Waccamaw River...   \n",
       "2        BOSTON– A $1-million settlement has been...   \n",
       "3    WASHINGTON—A federal grand jury in Las Vegas...   \n",
       "4  The U.S. Department of Justice, the U.S. Envir...   \n",
       "\n",
       "                        date         topics  \\\n",
       "0  2014-10-01T00:00:00-04:00             []   \n",
       "1  2012-07-25T00:00:00-04:00             []   \n",
       "2  2011-08-03T00:00:00-04:00             []   \n",
       "3  2010-01-08T00:00:00-05:00             []   \n",
       "4  2018-07-09T00:00:00-04:00  [Environment]   \n",
       "\n",
       "                                     components  \n",
       "0            [National Security Division (NSD)]  \n",
       "1  [Environment and Natural Resources Division]  \n",
       "2  [Environment and Natural Resources Division]  \n",
       "3  [Environment and Natural Resources Division]  \n",
       "4  [Environment and Natural Resources Division]  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7c11eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>contents</th>\n",
       "      <th>date</th>\n",
       "      <th>topics</th>\n",
       "      <th>components</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18-898</td>\n",
       "      <td>$100 Million Settlement Will Speed Cleanup Wor...</td>\n",
       "      <td>The U.S. Department of Justice, the U.S. Envir...</td>\n",
       "      <td>2018-07-09T00:00:00-04:00</td>\n",
       "      <td>[Environment]</td>\n",
       "      <td>[Environment and Natural Resources Division]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14-1412</td>\n",
       "      <td>14 Indicted in Connection with New England Com...</td>\n",
       "      <td>A 131-count criminal indictment was unsealed t...</td>\n",
       "      <td>2014-12-17T00:00:00-05:00</td>\n",
       "      <td>[Consumer Protection]</td>\n",
       "      <td>[Civil Division]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>17-1419</td>\n",
       "      <td>2017 Southeast Regional Animal Cruelty Prosecu...</td>\n",
       "      <td>The United States Attorney’s Office for the Mi...</td>\n",
       "      <td>2017-12-14T00:00:00-05:00</td>\n",
       "      <td>[Environment]</td>\n",
       "      <td>[Environment and Natural Resources Division, U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>15-1562</td>\n",
       "      <td>21st Century Oncology to Pay $19.75 Million to...</td>\n",
       "      <td>21st Century Oncology LLC, has agreed to pay $...</td>\n",
       "      <td>2015-12-18T00:00:00-05:00</td>\n",
       "      <td>[False Claims Act, Health Care Fraud]</td>\n",
       "      <td>[Civil Division]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>17-1404</td>\n",
       "      <td>21st Century Oncology to Pay $26 Million to Se...</td>\n",
       "      <td>21st Century Oncology Inc. and certain of its ...</td>\n",
       "      <td>2017-12-12T00:00:00-05:00</td>\n",
       "      <td>[Health Care Fraud, False Claims Act]</td>\n",
       "      <td>[Civil Division, USAO - Florida, Middle]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                              title  \\\n",
       "4    18-898  $100 Million Settlement Will Speed Cleanup Wor...   \n",
       "7   14-1412  14 Indicted in Connection with New England Com...   \n",
       "19  17-1419  2017 Southeast Regional Animal Cruelty Prosecu...   \n",
       "22  15-1562  21st Century Oncology to Pay $19.75 Million to...   \n",
       "23  17-1404  21st Century Oncology to Pay $26 Million to Se...   \n",
       "\n",
       "                                             contents  \\\n",
       "4   The U.S. Department of Justice, the U.S. Envir...   \n",
       "7   A 131-count criminal indictment was unsealed t...   \n",
       "19  The United States Attorney’s Office for the Mi...   \n",
       "22  21st Century Oncology LLC, has agreed to pay $...   \n",
       "23  21st Century Oncology Inc. and certain of its ...   \n",
       "\n",
       "                         date                                 topics  \\\n",
       "4   2018-07-09T00:00:00-04:00                          [Environment]   \n",
       "7   2014-12-17T00:00:00-05:00                  [Consumer Protection]   \n",
       "19  2017-12-14T00:00:00-05:00                          [Environment]   \n",
       "22  2015-12-18T00:00:00-05:00  [False Claims Act, Health Care Fraud]   \n",
       "23  2017-12-12T00:00:00-05:00  [Health Care Fraud, False Claims Act]   \n",
       "\n",
       "                                           components  \n",
       "4        [Environment and Natural Resources Division]  \n",
       "7                                    [Civil Division]  \n",
       "19  [Environment and Natural Resources Division, U...  \n",
       "22                                   [Civil Division]  \n",
       "23           [Civil Division, USAO - Florida, Middle]  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df[\"topics\"].str.len()!=0]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5efd45e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4688, 6)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fdf2c468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 6)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.head(100)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a8b7e08d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5504"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[\"contents\"].iloc[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "89ccd53f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>contents</th>\n",
       "      <th>date</th>\n",
       "      <th>topics</th>\n",
       "      <th>components</th>\n",
       "      <th>contents_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18-898</td>\n",
       "      <td>$100 Million Settlement Will Speed Cleanup Wor...</td>\n",
       "      <td>The U.S. Department of Justice, the U.S. Envir...</td>\n",
       "      <td>2018-07-09T00:00:00-04:00</td>\n",
       "      <td>[Environment]</td>\n",
       "      <td>[Environment and Natural Resources Division]</td>\n",
       "      <td>U.S. Department Justice U.S. Environmental Pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14-1412</td>\n",
       "      <td>14 Indicted in Connection with New England Com...</td>\n",
       "      <td>A 131-count criminal indictment was unsealed t...</td>\n",
       "      <td>2014-12-17T00:00:00-05:00</td>\n",
       "      <td>[Consumer Protection]</td>\n",
       "      <td>[Civil Division]</td>\n",
       "      <td>131 count criminal indictment unsealed today B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>17-1419</td>\n",
       "      <td>2017 Southeast Regional Animal Cruelty Prosecu...</td>\n",
       "      <td>The United States Attorney’s Office for the Mi...</td>\n",
       "      <td>2017-12-14T00:00:00-05:00</td>\n",
       "      <td>[Environment]</td>\n",
       "      <td>[Environment and Natural Resources Division, U...</td>\n",
       "      <td>United States Attorney Office Middle District ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>15-1562</td>\n",
       "      <td>21st Century Oncology to Pay $19.75 Million to...</td>\n",
       "      <td>21st Century Oncology LLC, has agreed to pay $...</td>\n",
       "      <td>2015-12-18T00:00:00-05:00</td>\n",
       "      <td>[False Claims Act, Health Care Fraud]</td>\n",
       "      <td>[Civil Division]</td>\n",
       "      <td>21st Century Oncology LLC agreed pay $ 19.75 m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>17-1404</td>\n",
       "      <td>21st Century Oncology to Pay $26 Million to Se...</td>\n",
       "      <td>21st Century Oncology Inc. and certain of its ...</td>\n",
       "      <td>2017-12-12T00:00:00-05:00</td>\n",
       "      <td>[Health Care Fraud, False Claims Act]</td>\n",
       "      <td>[Civil Division, USAO - Florida, Middle]</td>\n",
       "      <td>21st Century Oncology Inc. certain subsidiarie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                              title  \\\n",
       "4    18-898  $100 Million Settlement Will Speed Cleanup Wor...   \n",
       "7   14-1412  14 Indicted in Connection with New England Com...   \n",
       "19  17-1419  2017 Southeast Regional Animal Cruelty Prosecu...   \n",
       "22  15-1562  21st Century Oncology to Pay $19.75 Million to...   \n",
       "23  17-1404  21st Century Oncology to Pay $26 Million to Se...   \n",
       "\n",
       "                                             contents  \\\n",
       "4   The U.S. Department of Justice, the U.S. Envir...   \n",
       "7   A 131-count criminal indictment was unsealed t...   \n",
       "19  The United States Attorney’s Office for the Mi...   \n",
       "22  21st Century Oncology LLC, has agreed to pay $...   \n",
       "23  21st Century Oncology Inc. and certain of its ...   \n",
       "\n",
       "                         date                                 topics  \\\n",
       "4   2018-07-09T00:00:00-04:00                          [Environment]   \n",
       "7   2014-12-17T00:00:00-05:00                  [Consumer Protection]   \n",
       "19  2017-12-14T00:00:00-05:00                          [Environment]   \n",
       "22  2015-12-18T00:00:00-05:00  [False Claims Act, Health Care Fraud]   \n",
       "23  2017-12-12T00:00:00-05:00  [Health Care Fraud, False Claims Act]   \n",
       "\n",
       "                                           components  \\\n",
       "4        [Environment and Natural Resources Division]   \n",
       "7                                    [Civil Division]   \n",
       "19  [Environment and Natural Resources Division, U...   \n",
       "22                                   [Civil Division]   \n",
       "23           [Civil Division, USAO - Florida, Middle]   \n",
       "\n",
       "                                         contents_new  \n",
       "4   U.S. Department Justice U.S. Environmental Pro...  \n",
       "7   131 count criminal indictment unsealed today B...  \n",
       "19  United States Attorney Office Middle District ...  \n",
       "22  21st Century Oncology LLC agreed pay $ 19.75 m...  \n",
       "23  21st Century Oncology Inc. certain subsidiarie...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"contents_new\"] = df[\"contents\"].apply(preprocess)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "abf4ffae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4217"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[\"contents_new\"].iloc[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d5b9de57",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''\n",
    "Thor: Love and Thunder is a 2022 American superhero film based on Marvel Comics featuring the character Thor, produced by Marvel Studios and \n",
    "distributed by Walt Disney Studios Motion Pictures. It is the sequel to Thor: Ragnarok (2017) and the 29th film in the Marvel Cinematic Universe (MCU).\n",
    "The film is directed by Taika Waititi, who co-wrote the script with Jennifer Kaytin Robinson, and stars Chris Hemsworth as Thor alongside Christian Bale, Tessa Thompson,\n",
    "Jaimie Alexander, Waititi, Russell Crowe, and Natalie Portman. In the film, Thor attempts to find inner peace, but must return to action and recruit Valkyrie (Thompson),\n",
    "Korg (Waititi), and Jane Foster (Portman)—who is now the Mighty Thor—to stop Gorr the God Butcher (Bale) from eliminating all gods.\n",
    "'''\n",
    "\n",
    "doc = nlp(text)\n",
    "stop_words_count = 0\n",
    "total_words_count = 0\n",
    "\n",
    "for token in doc:\n",
    "    if token.is_stop:\n",
    "        stop_words_count += 1\n",
    "    total_words_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3d52cf20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total stop words in text are {40}\n",
      "Total words_count in text are {160}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total stop words in text are\",{stop_words_count})\n",
    "print(f\"Total words_count in text are\",{total_words_count})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b9154a2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentage_of_stop_words = (stop_words_count/total_words_count)*100\n",
    "percentage_of_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fb286c58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'india': 5,\n",
       " 'has': 2,\n",
       " 'launched': 8,\n",
       " 'chandrayaan3': 0,\n",
       " 'successfully': 11,\n",
       " 'india has': 6,\n",
       " 'has launched': 3,\n",
       " 'launched chandrayaan3': 9,\n",
       " 'chandrayaan3 successfully': 1,\n",
       " 'india has launched': 7,\n",
       " 'has launched chandrayaan3': 4,\n",
       " 'launched chandrayaan3 successfully': 10}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text Representation using Bag of n-Grams\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "v = CountVectorizer(ngram_range=(1,3))\n",
    "v.fit([\"India has launched chandrayaan3 successfully\"])\n",
    "v.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3ae9756d",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    \"Thor ate pizza\",\n",
    "    \"Loki is tall\",\n",
    "    \"Loki is eating pizza\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d9efba5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def preprocess(text):\n",
    "    doc = nlp(text)\n",
    "    filtered_tokens = []\n",
    "    for token in doc:\n",
    "        if token.is_stop or token.is_punct:\n",
    "            continue\n",
    "        filtered_tokens.append(token.lemma_)\n",
    "        \n",
    "    return \" \".join(filtered_tokens)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f6786a9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Loki eat pizza'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(\"Loki is eating pizza\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "59a1331f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thor eat pizza', 'Loki tall', 'Loki eat pizza']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_processed = [preprocess(text) for text in corpus]\n",
    "corpus_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6a0a941c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'thor': 7,\n",
       " 'eat': 0,\n",
       " 'pizza': 5,\n",
       " 'thor eat': 8,\n",
       " 'eat pizza': 1,\n",
       " 'loki': 2,\n",
       " 'tall': 6,\n",
       " 'loki tall': 4,\n",
       " 'loki eat': 3}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = CountVectorizer(ngram_range=(1,2))\n",
    "v.fit(corpus_processed)\n",
    "v.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e51bb545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 0, 0, 1, 0, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.transform([\"Thor eat pizza\"]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9cb47694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 0, 0, 1, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.transform([\"Hulk eat pizza \"]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "89e1d3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'thor': 25, 'eating': 10, 'pizza': 22, 'loki': 17, 'is': 16, 'ironman': 15, 'ate': 7, 'already': 0, 'apple': 5, 'announcing': 4, 'new': 20, 'iphone': 14, 'tomorrow': 26, 'tesla': 24, 'model': 19, 'google': 12, 'pixel': 21, 'microsoft': 18, 'surface': 23, 'amazon': 2, 'eco': 11, 'dot': 9, 'am': 1, 'biryani': 8, 'and': 3, 'you': 27, 'are': 6, 'grapes': 13}\n"
     ]
    }
   ],
   "source": [
    "# Text representation using TF-IDF\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "corpus = [\n",
    "    \"Thor eating pizza, Loki is eating pizza, Ironman ate pizza already\",\n",
    "    \"Apple is announcing new iphone tomorrow\",\n",
    "    \"Tesla is announcing new model-3 tomorrow\",\n",
    "    \"Google is announcing new pixel-6 tomorrow\",\n",
    "    \"Microsoft is announcing new surface tomorrow\",\n",
    "    \"Amazon is announcing new eco-dot tomorrow\",\n",
    "    \"I am eating biryani and you are eating grapes\"\n",
    "]\n",
    "\n",
    "v = TfidfVectorizer()\n",
    "tranfformed_output = v.fit_transform(corpus)\n",
    "print(v.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "dfa1997d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already 2.386294361119891\n",
      "am 2.386294361119891\n",
      "amazon 2.386294361119891\n",
      "and 2.386294361119891\n",
      "announcing 1.2876820724517808\n",
      "apple 2.386294361119891\n",
      "are 2.386294361119891\n",
      "ate 2.386294361119891\n",
      "biryani 2.386294361119891\n",
      "dot 2.386294361119891\n",
      "eating 1.9808292530117262\n",
      "eco 2.386294361119891\n",
      "google 2.386294361119891\n",
      "grapes 2.386294361119891\n",
      "iphone 2.386294361119891\n",
      "ironman 2.386294361119891\n",
      "is 1.1335313926245225\n",
      "loki 2.386294361119891\n",
      "microsoft 2.386294361119891\n",
      "model 2.386294361119891\n",
      "new 1.2876820724517808\n",
      "pixel 2.386294361119891\n",
      "pizza 2.386294361119891\n",
      "surface 2.386294361119891\n",
      "tesla 2.386294361119891\n",
      "thor 2.386294361119891\n",
      "tomorrow 1.2876820724517808\n",
      "you 2.386294361119891\n"
     ]
    }
   ],
   "source": [
    "all_feature_names = v.get_feature_names_out()\n",
    "\n",
    "for word in all_feature_names:\n",
    "    indx = v.vocabulary_.get(word)\n",
    "    print(f\"{word} {v.idf_[indx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a955aba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.24266547, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.24266547, 0.        , 0.        ,\n",
       "        0.40286636, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.24266547, 0.11527033, 0.24266547, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.72799642, 0.        , 0.        ,\n",
       "        0.24266547, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.30652086,\n",
       "        0.5680354 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.5680354 ,\n",
       "        0.        , 0.26982671, 0.        , 0.        , 0.        ,\n",
       "        0.30652086, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.30652086, 0.        ]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tranfformed_output.toarray()[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c2194482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Representation using Word Embeddings\n",
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d00e16c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dog Vector: True OOV: False\n",
      "cat Vector: True OOV: False\n",
      "eat Vector: True OOV: False\n",
      "banana Vector: True OOV: False\n",
      "asjdk Vector: False OOV: True\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Dog cat eat banana asjdk\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, \"Vector:\", token.has_vector, \"OOV:\", token.is_oov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "df55d085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[0].vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2cf73108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_token = nlp(\"bread\")\n",
    "doc.vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "46d4c955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bread <-> bread : 1.0\n",
      "sandwich <-> bread : 0.6341067010130894\n",
      "burger <-> bread : 0.47520687769584247\n",
      "car <-> bread : 0.06451532596945217\n",
      "tiger <-> bread : 0.04764611272488976\n",
      "human <-> bread : 0.2151154210812192\n",
      "wheat <-> bread : 0.615036141030184\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"bread sandwich burger car tiger human wheat\")\n",
    "\n",
    "for token in doc:\n",
    "    print(f\"{token.text} <-> {base_token.text} :\", token.similarity(base_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "91cbf2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printsimilarity(base_word, words_to_compare):\n",
    "    base_token = nlp(base_word)\n",
    "    doc = nlp(words_to_compare)\n",
    "    for token in doc:\n",
    "        print(f\"{token.text} <-> {base_token.text} :\", token.similarity(base_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3c6a2883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samsung <-> iphone : 0.6708590303423401\n",
      "apple <-> iphone : 0.4387907748060368\n",
      "iphone <-> iphone : 1.0\n",
      "car <-> iphone : 0.25586206064273004\n",
      "human <-> iphone : 0.009960269592946424\n",
      "cat <-> iphone : 0.11430552710784589\n"
     ]
    }
   ],
   "source": [
    "printsimilarity(\"iphone\", \"samsung apple iphone car human cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "adefac46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word vectors in Gensim\n",
    "\n",
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5c267b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv = api.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8d24feda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72915095"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.similarity(w1=\"great\", w2=\"good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "211c718a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('great', 0.7291510105133057),\n",
       " ('bad', 0.7190051078796387),\n",
       " ('terrific', 0.6889115571975708),\n",
       " ('decent', 0.6837348341941833),\n",
       " ('nice', 0.6836092472076416),\n",
       " ('excellent', 0.6442928910255432),\n",
       " ('fantastic', 0.6407778263092041),\n",
       " ('better', 0.6120728850364685),\n",
       " ('solid', 0.5806034207344055),\n",
       " ('lousy', 0.5764203071594238)]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(\"good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6dd490cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7118193507194519),\n",
       " ('monarch', 0.6189674735069275),\n",
       " ('princess', 0.5902431011199951),\n",
       " ('crown_prince', 0.5499460697174072),\n",
       " ('prince', 0.5377321243286133),\n",
       " ('kings', 0.5236844420433044),\n",
       " ('Queen_Consort', 0.5235945582389832),\n",
       " ('queens', 0.518113374710083),\n",
       " ('sultan', 0.5098593831062317),\n",
       " ('monarchy', 0.5087411999702454)]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(positive=[\"king\",\"woman\"], negative=[\"man\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47ca7a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
